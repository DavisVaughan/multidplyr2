---
output: github_document
editor_options: 
  chunk_output_type: console
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

![](https://img.shields.io/badge/lifecycle-experimental-brightgreen.svg)

# multidplyr2

`multidplyr2` is a revamp of `multidplyr` that uses a subset of the `future` 
package as the backend. The interface is essentially the same, but globals and packages
are automatically picked up and exported to each worker. If for some reason that
fails, you can fallback to exporting variables and packages manually.

The default is to use a local PSOCK cluster, but you can create a forked cluster on a 
Unix machine and use that instead. `future` has a nice `makeClusterPSOCK()` 
function that provides additional functionality for connecting to clusters on
external machines.

_There is still more work to do. I would like to update the internals from `lazyeval`
to `rlang`. There are a few warnings you might run into from outdated `dplyr` code,
but it still works.
I'm still thinking about what other benefits come from using `future`. 
It also needs documentation but if you know how to use `multidplyr`, 
you essentially know how to use this._ 

## Installation

You can install the released version of multidplyr2 from [CRAN](https://CRAN.R-project.org) with:

``` {r, eval=FALSE}
# No you cannot
install.packages("multidplyr2")
```

And the development version from [GitHub](https://github.com/) with:

``` {r, eval=FALSE}
# install.packages("devtools")
devtools::install_github("DavisVaughan/multidplyr2")
```

# Example

```{r, message=FALSE, warning=FALSE, echo=FALSE}
library(multidplyr2)
iris <- as_tibble(iris)
set.seed(123)
```

Let's partition `iris` by `Species`.

```{r}
iris_part <- partition(iris, Species)

iris_part
```


We can load libraries and create variables like normal, write code that works
on our local copy of the data, then just replace the local variable name with
the partitioned variable name and the same code works, but now in parallel.

```{r}
# Library like normal. Make variables like normal
library(purrr)
x <- 1
```

Run locally to make sure things are working. 

```{r}
iris %>% mutate(y = map_dbl(Petal.Width, ~ .x + 2 * x))
```

Switch out the local variable name for the partitioned one. Rows are scrambled
so don't let that mess with you.

__Note that the `purrr` package and the `x` variable are automatically exported
for you by `future`!__

```{r}
iris_part %>% mutate(y = map_dbl(Petal.Width, ~ .x + 2 * x))
```

# Example 2

We can still export things manually if needed.

```{r}
.cl <- iris_part$cluster
cluster_assign_value(.cl, "my_remote_var", 2)

iris_part %>%
  mutate(remote_var = my_remote_var)
```

# Fake Example

Theoretically we could take the example from `?future::makeClusterPSOCK()` and 
create all kinds of different clusters to use here. One example is an AWS EC2 running
one of the RStudio AMI's from Louis Aslett. The code is from the help doc above
and outlines how one could use this.

```{r, eval=FALSE}
## Launching worker on Amazon AWS EC2 running one of the
## Amazon Machine Images (AMI) provided by RStudio
## (http://www.louisaslett.com/RStudio_AMI/)
public_ip <- "1.2.3.4"
ssh_private_key_file <- "~/.ssh/my-private-aws-key.pem"
cl <- makeClusterPSOCK(
  ## Public IP number of EC2 instance
  public_ip,
  ## User name (always 'ubuntu')
  user = "ubuntu",
  ## Use private SSH key registered with AWS
  rshopts = c(
    "-o", "StrictHostKeyChecking=no",
    "-o", "IdentitiesOnly=yes",
    "-i", ssh_private_key_file
  ),
  ## Set up .libPaths() for the 'ubuntu' user and
  ## install future package
  rscript_args = c(
    "-e", shQuote("local({
      p <- Sys.getenv('R_LIBS_USER')
      dir.create(p, recursive = TRUE, showWarnings = FALSE)
      .libPaths(p)
    })"),
    "-e", shQuote("install.packages('future')")
  ),
  dryrun = TRUE
)


iris_part <- partition(iris, Species, cluster = cl)
```

